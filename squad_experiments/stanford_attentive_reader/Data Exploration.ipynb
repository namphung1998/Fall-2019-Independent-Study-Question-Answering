{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(5, 10, 5)\n",
    "b = torch.randn(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(a, torch.unsqueeze(b, -1)).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = Attention(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = torch.randn(5, 10, 5)\n",
    "question = torch.randn(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_masks = torch.ones(5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "y = attn(context, question, c_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(4, 8, 2, batch_first=True, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(4, 8, num_layers=2, batch_first=True, bidirectional=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(16, 50, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_hiddens, (last_hidden, last_cell) = lstm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 8])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0756,  0.3650,  0.1049,  0.7143,  0.4492,  0.0047,  0.2538, -0.3036],\n",
       "        [ 0.1978,  0.2315, -0.1213,  0.6307,  0.4466,  0.1287,  0.4813, -0.3917],\n",
       "        [ 0.1631,  0.4547,  0.0711,  0.6993,  0.3347, -0.0234,  0.0198, -0.3717],\n",
       "        [-0.0489,  0.2809, -0.2687,  0.1883,  0.8884,  0.1614,  0.3801,  0.1723],\n",
       "        [ 0.0248,  0.3087, -0.1665,  0.2899,  0.6648,  0.0948,  0.4430,  0.0098],\n",
       "        [-0.0727,  0.5039,  0.1640,  0.6035,  0.1769, -0.0511,  0.0591, -0.2064],\n",
       "        [ 0.0156,  0.4106, -0.0347,  0.3331,  0.7090,  0.0167,  0.2693, -0.1186],\n",
       "        [ 0.0270,  0.2973,  0.0574,  0.6313,  0.4115,  0.0887,  0.1568, -0.3718],\n",
       "        [ 0.1979,  0.2377, -0.2911,  0.5336,  0.1433,  0.1336,  0.4198, -0.4103],\n",
       "        [-0.2162,  0.4587,  0.1561,  0.3004,  0.6123,  0.0840,  0.2226, -0.1264],\n",
       "        [ 0.0880,  0.3230, -0.0141,  0.5449,  0.6445,  0.0064,  0.1134,  0.1163],\n",
       "        [-0.2330,  0.4801, -0.0165,  0.1833,  0.7101,  0.2217,  0.6785, -0.1867],\n",
       "        [-0.4895,  0.4720,  0.1897,  0.2293,  0.7099,  0.1079,  0.4112,  0.0966],\n",
       "        [-0.4589,  0.3170, -0.0137,  0.2421,  0.6781, -0.0764,  0.4264, -0.0622],\n",
       "        [ 0.0600,  0.3470,  0.1576,  0.3879,  0.6624,  0.0156,  0.2299, -0.0741],\n",
       "        [-0.0743,  0.4182, -0.1216,  0.3832,  0.5848,  0.2755,  0.5148, -0.3604]],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
